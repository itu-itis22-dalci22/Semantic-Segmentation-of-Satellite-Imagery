{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import numpy as np\n",
    "label_map = np.array([\n",
    "      (0, 0, 0),          # 0 - Background (Black)\n",
    "      (0, 0, 255),        # 1 - Surface water (Blue)\n",
    "      (135, 206, 250),    # 2 - Street (Light Sky Blue)\n",
    "      (255, 255, 0),      # 3 - Urban Fabric (Yellow)\n",
    "      (128, 0, 0),        # 4 - Industrial, commercial and transport (Maroon)\n",
    "      (139, 37, 0),       # 5 - Mine, dump, and construction sites (Reddish Brown)\n",
    "      (0, 128, 0),        # 6 - Artificial, vegetated areas (Green)\n",
    "      (255, 165, 0),      # 7 - Arable Land (Orange)\n",
    "      (0, 255, 0),        # 8 - Permanent Crops (Lime Green)\n",
    "      (154, 205, 50),     # 9 - Pastures (Yellow Green)\n",
    "      (34, 139, 34),      # 10 - Forests (Forest Green)\n",
    "      (139, 69, 19),      # 11 - Shrub (Saddle Brown)\n",
    "      (245, 245, 220),    # 12 - Open spaces with no vegetation (Beige)\n",
    "      (0, 255, 255),      # 13 - Inland wetlands (Cyan)\n",
    "  ])\n",
    "\n",
    "\n",
    "labels = [\n",
    "    \"Background\", \"Surface water\", \"Street\", \"Urban Fabric\", \"Industrial, commercial and transport\",\n",
    "    \"Mine, dump, and construction sites\", \"Artificial, vegetated areas\", \"Arable Land\",\n",
    "    \"Permanent Crops\", \"Pastures\", \"Forests\", \"Shrub\", \"Open spaces with no vegetation\", \"Inland wetlands\"\n",
    "]\n",
    "\n",
    "def predict_and_show(model, dataset, index):\n",
    "  X, mask = dataset[index]\n",
    "  X = X.to(device)\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    output = model(X.unsqueeze(dim=0)).to(device)\n",
    "\n",
    "  W, H = output.shape[2], output.shape[3]\n",
    "\n",
    "  # Get RGB segmentation map\n",
    "  segmented_image = draw_segmentation_map(output)\n",
    "\n",
    "  # Resize to original image size\n",
    "  segmented_image = cv2.resize(segmented_image, (W, H), cv2.INTER_LINEAR)\n",
    "\n",
    "  # Plot\n",
    "  plt.figure(figsize=(20, 20))\n",
    "\n",
    "  plt.subplot(1, 3, 1)\n",
    "  # Create a custom colormap using the colors defined above\n",
    "  cmap = ListedColormap(label_map / 255.0)\n",
    "\n",
    "  # Display the mask using the custom colormap\n",
    "  plt.imshow(mask, cmap=cmap, vmin=0, vmax=13)\n",
    "\n",
    "  plt.title(\"Ground Truth\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "  plt.subplot(1, 3, 2)\n",
    "  plt.title(\"Segmentation\")\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(segmented_image)\n",
    "\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "  # Save Segmented and overlayed images\n",
    "  if False:\n",
    "      cv2.imwrite(seg_map_save_dir, segmented_image[:, :, ::-1])\n",
    "      cv2.imwrite(overlayed_save_dir, overlayed_image)\n",
    "\n",
    "\n",
    "\n",
    "def predict_random_and_show(model, dataset):\n",
    "    indices = random.sample(range(len(dataset)), 6)  # Change max_index to the maximum index available in your dataset\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "\n",
    "    for idx, index in enumerate(indices, 1):\n",
    "        X, mask = dataset[index]\n",
    "        X = X.to(device)\n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            output = model(X.unsqueeze(dim=0)).to(device)\n",
    "\n",
    "        W, H = output.shape[2], output.shape[3]\n",
    "\n",
    "        # Get RGB segmentation map\n",
    "        segmented_image = draw_segmentation_map(output)\n",
    "\n",
    "        # Resize to original image size\n",
    "        segmented_image = cv2.resize(segmented_image, (W, H), cv2.INTER_LINEAR)\n",
    "\n",
    "        plt.subplot(6, 3, 3 * (idx - 1) + 1)\n",
    "        cmap = ListedColormap(label_map / 255.0)\n",
    "        plt.imshow(mask, cmap=cmap, vmin=0, vmax=13)\n",
    "        plt.title(f\"Ground Truth - Image {index}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(6, 3, 3 * (idx - 1) + 2)\n",
    "        plt.title(f\"Segmentation - Image {index}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(segmented_image)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def show_mask(mask):\n",
    "  cmap = ListedColormap(label_map / 255.0)\n",
    "\n",
    "  plt.imshow(mask, cmap=cmap, vmin=0, vmax=13)\n",
    "\n",
    "  num_labels = len(label_map)\n",
    "  ticks = np.arange(num_labels)\n",
    "\n",
    "  cbar = plt.colorbar(ticks=ticks)\n",
    "  cbar.ax.set_yticklabels(labels, fontsize=8)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def draw_segmentation_map(outputs):\n",
    "    labels = torch.argmax(outputs.squeeze(), dim=0).cpu().numpy()\n",
    "\n",
    "    red_map   = np.zeros_like(labels).astype(np.uint8)\n",
    "    green_map = np.zeros_like(labels).astype(np.uint8)\n",
    "    blue_map  = np.zeros_like(labels).astype(np.uint8)\n",
    "\n",
    "    for label_num in range(0, len(label_map)):\n",
    "        index = labels == label_num\n",
    "\n",
    "        R, G, B = label_map[label_num]\n",
    "\n",
    "        red_map[index]   = R\n",
    "        green_map[index] = G\n",
    "        blue_map[index]  = B\n",
    "\n",
    "    segmentation_map = np.stack([red_map, green_map, blue_map], axis=2)\n",
    "    return segmentation_map"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
