{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_accuracy(pred, target):\n",
    "  _, predicted = torch.max(pred, 1)\n",
    "  correct_pixels = (predicted == target).sum().item()\n",
    "  total_pixels = target.numel()\n",
    "  accuracy = correct_pixels / total_pixels * 100\n",
    "  return accuracy\n",
    "\n",
    "from torchmetrics import F1Score\n",
    "def calculate_f1(pred, target, num_classes):\n",
    "  f1 = F1Score(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "  return f1(pred.to(device), target.to(device))\n",
    "\n",
    "\n",
    "from torchmetrics import JaccardIndex\n",
    "def calculate_iou(output, mask, num_classes):\n",
    "  output = output.to(device)\n",
    "  mask = mask.to(device)\n",
    "\n",
    "  jaccard = JaccardIndex(task=\"multiclass\", num_classes=num_classes, average=\"weighted\").to(device)\n",
    "  return jaccard(output, mask)\n",
    "\n",
    "from torchmetrics import Precision\n",
    "def calculate_precision(output, mask, num_classes):\n",
    "  precision = Precision(task=\"multiclass\", num_classes=num_classes, average=\"weighted\").to(device)\n",
    "  return precision(output.to(device), mask.to(device))\n",
    "\n",
    "from torchmetrics import Recall\n",
    "def calculate_recall(output, mask, num_classes):\n",
    "  recall = Recall(task=\"multiclass\", num_classes=num_classes, average=\"weighted\").to(device)\n",
    "  return recall(output.to(device), mask.to(device))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
